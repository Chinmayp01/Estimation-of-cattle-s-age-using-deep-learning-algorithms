{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17006,
     "status": "ok",
     "timestamp": 1710042163478,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "KKH8LWPvdDnZ",
    "outputId": "1cdfc16c-67a7-4df8-80a6-86baef463b10"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1710042163478,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "pv2mXBpkcrCG",
    "outputId": "06581d1e-9cff-454a-e284-3f21d07b2394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Welcome\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29806,
     "status": "ok",
     "timestamp": 1710042208955,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "NIqBwbD4c-Cb",
    "outputId": "42c70d9d-9640-433d-a630-f73e3d519055"
   },
   "outputs": [],
   "source": [
    "def unzip(file):\n",
    "    with zipfile.ZipFile(file ,'r') as zip:\n",
    "        zip.extractall()\n",
    "        print(\"Files extracted successfully....\")\n",
    "\n",
    "unzip('Cattle_DataSet_15_Classes_yolo_dataset-20240312T134950Z-001.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8070,
     "status": "ok",
     "timestamp": 1710042266784,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "46rwPBnocrCJ",
    "outputId": "02d26ded-13ef-4f9d-ddb1-3acf43eb7c75"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "first_folder = 'Cattle_DataSet_15_Classes_yolo_dataset'\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "  count_images = 0\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    count_images += len(filenames)\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "  print(f\"Total Images : {count_images}\")\n",
    "walk_through_dir(first_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1710042299366,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "kvbPe9xhcrCJ",
    "outputId": "711843ee-3b31-447c-dc57-d0ee5d397f71"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE =(224 , 224)\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_dir = \"Cattle_DataSet_15_Classes_yolo_dataset/train/\"\n",
    "val_dir = \"Cattle_DataSet_15_Classes_yolo_dataset/val/\"\n",
    "test_dir = \"Cattle_DataSet_15_Classes_yolo_dataset/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255. , rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training images:\")\n",
    "train_data =train_datagen.flow_from_directory(train_dir ,\n",
    "                                              target_size =IMAGE_SHAPE,\n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              class_mode =\"categorical\",\n",
    "                                              shuffle = True\n",
    "\n",
    "                                              )\n",
    "print(\"Training images:\")\n",
    "val_data =val_datagen.flow_from_directory(val_dir ,\n",
    "                                              target_size =IMAGE_SHAPE,\n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              class_mode =\"categorical\",\n",
    "                                              shuffle = True)\n",
    "print(\"Testing images:\")\n",
    "test_data =test_datagen.flow_from_directory(test_dir ,\n",
    "                                              target_size =IMAGE_SHAPE,\n",
    "                                              batch_size = 1,\n",
    "                                              class_mode =\"categorical\",\n",
    "                                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1710042304695,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "YP4pewvXcrCK",
    "outputId": "6f60b447-85c3-4a98-d1b6-d5f4ebb08924"
   },
   "outputs": [],
   "source": [
    "# Getting Class Names\n",
    "# Define class labels\n",
    "labels = test_data.class_indices.keys()\n",
    "labels = list(labels)\n",
    "class_names = labels\n",
    "print(f\"Class Names : {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710042306254,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "bclIuzlzcrCK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_tensorboard_callback(experiment_name, dir_name = \"Model_Results/LogsDirectory\"):\n",
    "  \"\"\"\n",
    "  Creates a TensorBoard callback instand to store log files.\n",
    "\n",
    "  Stores log files with the filepath:\n",
    "    \"dir_name/experiment_name/current_datetime/\"\n",
    "\n",
    "  Args:\n",
    "    dir_name: target directory to store TensorBoard log files\n",
    "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
    "  \"\"\"\n",
    "  log_dir = dir_name + \"/\" + experiment_name\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1710042432059,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "rcMefT-qcrCL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(history , file_name , save_dir = \"Model_Results/Accuracy_Curves\"):\n",
    "    # Get training and validation loss values\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Get training and validation accuracy values\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Plot the loss curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the accuracy curves\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(accuracy, label='Training Accuracy')\n",
    "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir ,file_name))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1710044927553,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "TWcWYOWTcrCL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix , classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_multiclass(y_true, y_pred , labels):\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Compute precision\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Compute recall\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "    return accuracy, precision, recall , report\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, File_Name, save_dir=\"Model_Results/ConfusionMatrix\"):\n",
    "    fig, ax = plt.subplots(figsize=(16,12))\n",
    "    cax = ax.matshow(cm, cmap='Blues')\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(cax)\n",
    "\n",
    "    # Set labels\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    ax.xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "    # Set labels at ticks\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "\n",
    "    # Display values in each cell\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "\n",
    "    # Save plot\n",
    "    plt.savefig(os.path.join(save_dir, File_Name))\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1710047621993,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "2jmlLp_GcrCM"
   },
   "outputs": [],
   "source": [
    "def load_and_prep_image(filename, img_shape=224, scale=False):\n",
    "  \"\"\"\n",
    "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
    "  (224, 224, 3).\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  filename (str): string filename of target image\n",
    "  img_shape (int): size to resize target image to, default 224\n",
    "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
    "  \"\"\"\n",
    "  # Read in the image\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Decode it into a tensor\n",
    "  img = tf.io.decode_image(img , channels=3)\n",
    "\n",
    "  # Resize the image\n",
    "  img = tf.image.resize(img, [img_shape, img_shape])\n",
    "  if scale:\n",
    "    # Rescale the image (get all values between 0 and 1)\n",
    "    return img/255.\n",
    "  else:\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1710047959642,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "pu0cxZ-6crCM"
   },
   "outputs": [],
   "source": [
    "# Make preds on a series of random images\n",
    "import os\n",
    "import random\n",
    "\n",
    "def Some_Predictions_on_Test_Data(test_dir , class_names , model , scale ,file_name , save_dir =\"Model_Results/Some_Predictions\" ):\n",
    "        plt.figure(figsize=(17,10))\n",
    "        for i in range(6):\n",
    "          # Choose a random image from a random class\n",
    "          class_name = random.choice(class_names)\n",
    "          filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n",
    "          filepath = test_dir + class_name + \"/\" + filename\n",
    "\n",
    "          # Load the image and make predictions\n",
    "          img = load_and_prep_image(filepath, scale=True) # don't scale images for EfficientNet predictions\n",
    "          pred_prob = model.predict(tf.expand_dims(img, axis=0)) # model accepts tensors of shape [None, 224, 224, 3]\n",
    "          pred_class = class_names[pred_prob.argmax()] # find the predicted class\n",
    "\n",
    "\n",
    "          new_image = img\n",
    "\n",
    "          plt.subplot(3,2, i+1)\n",
    "          plt.imshow(new_image)\n",
    "          if class_name == pred_class: # Change the color of text based on whether prediction is right or wrong\n",
    "            title_color = \"g\"\n",
    "          else:\n",
    "            title_color = \"r\"\n",
    "          plt.title(f\"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}\", c=title_color)\n",
    "          plt.axis(False)\n",
    "        plt.savefig(os.path.join(save_dir , file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710044930770,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "DMldpdFtcrCN"
   },
   "outputs": [],
   "source": [
    "def Ploting_Confusion_matrix( test_data , model,File_Name ,save_dir = \"Model_Results/ConfusionMatrix\"):\n",
    "    # Example usage:\n",
    "    # Generate example data\n",
    "\n",
    "    y_true = test_data.classes\n",
    "    pred_prob = model.predict(test_data)\n",
    "    y_pred = pred_prob.argmax(axis = 1)\n",
    "    # Define class labels\n",
    "    labels = test_data.class_indices.keys()\n",
    "    labels = list(labels)\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy, precision, recall , report  = evaluate_multiclass(y_true, y_pred , labels )\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    report = pd.DataFrame(report).transpose()\n",
    "    report.to_csv('Model_Results/ClassificationReport/' + File_Name)\n",
    "\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, labels, File_Name , save_dir)\n",
    "\n",
    "    return accuracy , precision , recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1710042501288,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "pF3LZ1qccrCN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_empty_csv_with_columns(column_names, csv_filename):\n",
    "    \"\"\"\n",
    "    Create an empty CSV file with specified column names.\n",
    "\n",
    "    Args:\n",
    "    - column_names: a list of column names\n",
    "    - csv_filename: the filename for the CSV file to save\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Example column names\n",
    "column_names = [\"Model_name\", \"accuracy\", \"precision\", \"recall\", \"training_time\", \"epochs\"]\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Create empty CSV file with specified column names\n",
    "create_empty_csv_with_columns(column_names, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1710042537201,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "morFFPuOcrCO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def append_row_to_dataframe(data, csv_filename):\n",
    "    \"\"\"\n",
    "    Append a row to a DataFrame and save it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    - data: a dictionary where keys are column names and values are the corresponding values for the new row\n",
    "    - csv_filename: the filename for the CSV file to append the row\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(\"CSV file not found.\")\n",
    "        return\n",
    "    data = pd.DataFrame(data)\n",
    "    df = pd.concat([df,data])\n",
    "    print(df)\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWHSDXDHcrCO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "\n",
    "\n",
    "    base_model = InceptionV3(input_shape = (224 ,224 , 3), include_top = False, weights = 'imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "    for layer in base_model.layers[: -30]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Add a final softmax layer with 4 node for classification output\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape for image data (height, width, channels)\n",
    "num_classes = test_data.num_classes # Example number of classes\n",
    "\n",
    "# Create the CNN model\n",
    "model2 = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint(filepath='Model_Results/Model_checkpoints/model_2.h5', monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_callback = create_tensorboard_callback(experiment_name=\"Model_2\")\n",
    "# Train the model with callbacks\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "history2 = model2.fit(train_data,\n",
    "                    epochs=80,\n",
    "                    validation_data=val_data,\n",
    "                    callbacks=[ model_checkpoint , tensorboard_callback , early_stopping])\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# # Save training time to a file\n",
    "# with open('Model_Results/training_time.txt', 'w') as file:\n",
    "#     file.write(f\"Total training time model 2: {training_time} seconds\\n\")\n",
    "\n",
    "# Print model summary\n",
    "model2.summary()\n",
    "model2.save('Model_Results/Models/Model_files/model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1710044456911,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "G_sx1x2McrCO",
    "outputId": "36836250-02c0-4a00-9206-0f38a1a2e55a"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history2 , 'model_2' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31226,
     "status": "ok",
     "timestamp": 1710045481581,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "Q_H9mxTLcrCP"
   },
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.load_model('Model_Results/Models/Model_files/model_2')\n",
    "model2.load_weights('Model_Results/Model_checkpoints/model_2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "executionInfo": {
     "elapsed": 144799,
     "status": "ok",
     "timestamp": 1710048158957,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "R5lyFVFInzmZ",
    "outputId": "7280bb6a-18d0-4fd7-c685-826165ec863a"
   },
   "outputs": [],
   "source": [
    "accuracy , precision , recall = Ploting_Confusion_matrix(test_data , model2 , 'model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "executionInfo": {
     "elapsed": 3363,
     "status": "ok",
     "timestamp": 1710047969821,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "0DeOcROrwNqG",
    "outputId": "57e95d3a-918f-424a-c8ad-99b4bd6bd695"
   },
   "outputs": [],
   "source": [
    "Some_Predictions_on_Test_Data(test_dir , class_names , model2 , True ,'Model_2' , save_dir =\"Model_Results/Some_Predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1710045497599,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "J8hB17wJcrCP",
    "outputId": "e6122ebd-76a9-4a33-b7ff-c1d537e8749d"
   },
   "outputs": [],
   "source": [
    "# Example data to append\n",
    "num_epochs_trained = len(history2.history['loss'])\n",
    "new_row_data = {\"Model_name\": [\"Inceptionv3 (30 layers unfreezed)\"], \"accuracy\": [accuracy], \"precision\": [precision], \"recall\": [recall], \"training_time\": [training_time], \"epochs\": [num_epochs_trained]}\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Append row to DataFrame and save to CSV\n",
    "append_row_to_dataframe(new_row_data, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtfvCd5TcrCP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e6Fkiwspfpm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJbOT1KopfmI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "\n",
    "\n",
    "    base_model = InceptionV3(input_shape = (224 ,224 , 3), include_top = False, weights = 'imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Add a final softmax layer with 4 node for classification output\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape for image data (height, width, channels)\n",
    "num_classes = test_data.num_classes # Example number of classes\n",
    "\n",
    "# Create the CNN model\n",
    "model3 = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint(filepath='Model_Results/Model_checkpoints/model_3.h5', monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_callback = create_tensorboard_callback( experiment_name=\"Model3\")\n",
    "# Train the model with callbacks\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "history3 = model3.fit(train_data,\n",
    "                    epochs=80,\n",
    "                    validation_data=val_data,\n",
    "                    callbacks=[ model_checkpoint , tensorboard_callback,early_stopping])\n",
    "# End time\n",
    "end_time = time.time()\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# # Save training time to a file\n",
    "# with open('Model_Results/training_time.txt', 'w') as file:\n",
    "#     file.write(f\"Total training time model 3: {training_time} seconds\\n\")\n",
    "# Print model summary\n",
    "model3.summary()\n",
    "\n",
    "model3.save('Model_Results/Models/Model_files/model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "error",
     "timestamp": 1710045573639,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "9G_vajAypfjW",
    "outputId": "1d25ffd9-5876-4b76-cdab-41baa90d981a"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history3 , 'model_3' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGCWKpAhpfgy"
   },
   "outputs": [],
   "source": [
    "model3 = tf.keras.models.load_model('Model_Results/Models/Model_files/model_3')\n",
    "model3.load_weights('Model_Results/Model_checkpoints/model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Tl2SX0YpfeX"
   },
   "outputs": [],
   "source": [
    "accuracy , precision , recall = Ploting_Confusion_matrix(test_data , model3 , 'model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4t11qKgzgc9"
   },
   "outputs": [],
   "source": [
    "Some_Predictions_on_Test_Data(test_dir , class_names , model3 , True ,'Model_3' , save_dir =\"Model_Results/Some_Predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhC48HS3p3BY"
   },
   "outputs": [],
   "source": [
    "# Example data to append\n",
    "num_epochs_trained = len(history3.history['loss'])\n",
    "new_row_data = {\"Model_name\": [\"Inceptionv3\"], \"accuracy\": [accuracy], \"precision\": [precision], \"recall\": [recall], \"training_time\": [training_time], \"epochs\": [num_epochs_trained]}\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Append row to DataFrame and save to CSV\n",
    "append_row_to_dataframe(new_row_data, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vz3yJ_HqArm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0McMFzDqAf-"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "\n",
    "\n",
    "    base_model = InceptionResNetV2(input_shape = (224 ,224 , 3), include_top = False, weights = 'imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    ## Add a final softmax layer with 4 node for classification output\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape for image data (height, width, channels)\n",
    "num_classes = test_data.num_classes # Example number of classes\n",
    "\n",
    "# Create the CNN model\n",
    "model4 = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model4.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint(filepath='Model_Results/Model_checkpoints/model_4.h5', monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_callback = create_tensorboard_callback( experiment_name=\"Model4\")\n",
    "# Train the model with callbacks\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "history4 = model4.fit(train_data,\n",
    "                    epochs=80,\n",
    "                    validation_data=val_data,\n",
    "                    callbacks=[ model_checkpoint , tensorboard_callback,early_stopping])\n",
    "# End time\n",
    "end_time = time.time()\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Save training time to a file\n",
    "with open('Model_Results/training_time.txt', 'w') as file:\n",
    "    file.write(f\"Total training time model 4: {training_time} seconds\\n\")\n",
    "# Print model summary\n",
    "model4.summary()\n",
    "\n",
    "model4.save('Model_Results/Models/Model_files/model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 1004,
     "status": "error",
     "timestamp": 1710045709597,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "GN1pI1PsqAcj",
    "outputId": "f91367a3-ed19-4e3c-ca76-2c8cb29f6d23"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history4 , 'model_4' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH55Y42PqAZL"
   },
   "outputs": [],
   "source": [
    "model4 = tf.keras.models.load_model('Model_Results/Models/Model_files/model_4')\n",
    "model4.load_weights('Model_Results/Model_checkpoints/model_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qvfq-3PqAWL"
   },
   "outputs": [],
   "source": [
    "accuracy , precision , recall = Ploting_Confusion_matrix(test_data , model4 , 'model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r09WHScIzkXe"
   },
   "outputs": [],
   "source": [
    "Some_Predictions_on_Test_Data(test_dir , class_names , model4 , True ,'Model_4' , save_dir =\"Model_Results/Some_Predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CF9i30ZVqATF"
   },
   "outputs": [],
   "source": [
    "# Example data to append\n",
    "num_epochs_trained = len(history4.history['loss'])\n",
    "new_row_data = {\"Model_name\": [\"InceptionResnet\"], \"accuracy\": [accuracy], \"precision\": [precision], \"recall\": [recall], \"training_time\": [training_time], \"epochs\": [num_epochs_trained]}\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Append row to DataFrame and save to CSV\n",
    "append_row_to_dataframe(new_row_data, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtmLF8tyqeuG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHcLFi1Iqeqk"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "\n",
    "\n",
    "    base_model =ResNet50V2(input_shape = (224 ,224 , 3), include_top = False, weights = 'imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Add a final softmax layer with 4 node for classification output\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape for image data (height, width, channels)\n",
    "num_classes = test_data.num_classes # Example number of classes\n",
    "\n",
    "# Create the CNN model\n",
    "model5 = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model5.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint(filepath='Model_Results/Model_checkpoints/model_5.h5', monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_callback = create_tensorboard_callback(experiment_name=\"Model5\")\n",
    "# Train the model with callbacks\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "history5 = model5.fit(train_data,\n",
    "                    epochs=80,\n",
    "                    validation_data=val_data,\n",
    "                    callbacks=[ model_checkpoint , tensorboard_callback,early_stopping])\n",
    "# End time\n",
    "end_time = time.time()\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Save training time to a file\n",
    "with open('Model_Results/training_time.txt', 'w') as file:\n",
    "    file.write(f\"Total training time model 5: {training_time} seconds\\n\")\n",
    "# Print model summary\n",
    "model5.summary()\n",
    "\n",
    "model5.save('Model_Results/Models/Model_files/model_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "error",
     "timestamp": 1710045843703,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "5avicvdRqelE",
    "outputId": "0af79938-f1fb-47e9-f7a5-1bb4f2a7c6be"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history5 , 'model_5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xg9E63wFqehl"
   },
   "outputs": [],
   "source": [
    "model5 = tf.keras.models.load_model('Model_Results/Models/Model_files/model_5')\n",
    "model5.load_weights('Model_Results/Model_checkpoints/model_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiSnbD2vqeYv"
   },
   "outputs": [],
   "source": [
    "accuracy , precision , recall = Ploting_Confusion_matrix(test_data , model5 , 'model_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9A3UZhIIzobk"
   },
   "outputs": [],
   "source": [
    "Some_Predictions_on_Test_Data(test_dir , class_names , model5 , True ,'Model_5' , save_dir =\"Model_Results/Some_Predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_F7FiENqeVP"
   },
   "outputs": [],
   "source": [
    "# Example data to append\n",
    "num_epochs_trained = len(history5.history['loss'])\n",
    "new_row_data = {\"Model_name\": [\"Resnet50v2\"], \"accuracy\": [accuracy], \"precision\": [precision], \"recall\": [recall], \"training_time\": [training_time], \"epochs\": [num_epochs_trained]}\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Append row to DataFrame and save to CSV\n",
    "append_row_to_dataframe(new_row_data, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdQ_YKxkq89z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMqfz1Zgq_A6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    base_model = VGG16(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "    x = layers.Flatten()(base_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape for image data (height, width, channels)\n",
    "num_classes = test_data.num_classes # Example number of classes\n",
    "\n",
    "# Create the CNN model\n",
    "model6 = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model6.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint(filepath='Model_Results/Model_checkpoints/model_6.h5', monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_callback = create_tensorboard_callback(experiment_name=\"Model6\")\n",
    "# Train the model with callbacks\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "history6 = model6.fit(train_data,\n",
    "                    epochs=80,\n",
    "                    validation_data=val_data,\n",
    "                    callbacks=[ model_checkpoint , tensorboard_callback,early_stopping])\n",
    "# End time\n",
    "end_time = time.time()\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Save training time to a file\n",
    "with open('Model_Results/training_time.txt', 'w') as file:\n",
    "    file.write(f\"Total training time model 6: {training_time} seconds\\n\")\n",
    "# Print model summary\n",
    "model6.summary()\n",
    "\n",
    "model6.save('Model_Results/Models/Model_files/model_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1710045944890,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "CDlIy-P9q-9V",
    "outputId": "923aaa44-4b76-4c17-fa83-0f1103d27f62"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history6 , 'model_6' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZf4hqnlq-6w"
   },
   "outputs": [],
   "source": [
    "model6 = tf.keras.models.load_model('Model_Results/Models/Model_files/model_6')\n",
    "model6.load_weights('Model_Results/Model_checkpoints/model_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXykDjSqq-uc"
   },
   "outputs": [],
   "source": [
    "accuracy , precision , recall = Ploting_Confusion_matrix(test_data , model6 , 'model_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-HANRIEztMR"
   },
   "outputs": [],
   "source": [
    "Some_Predictions_on_Test_Data(test_dir , class_names , model6 , True ,'Model_6' , save_dir =\"Model_Results/Some_Predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYumEoyqq-rG"
   },
   "outputs": [],
   "source": [
    "# Example data to append\n",
    "num_epochs_trained = len(history6.history['loss'])\n",
    "new_row_data = {\"Model_name\": [\"VGG Net\"], \"accuracy\": [accuracy], \"precision\": [precision], \"recall\": [recall], \"training_time\": [training_time], \"epochs\": [num_epochs_trained]}\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Append row to DataFrame and save to CSV\n",
    "append_row_to_dataframe(new_row_data, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UafVVw_q-ol"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QE0tyrrfq-mF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    base_model = MobileNet(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape for image data (height, width, channels)\n",
    "num_classes = test_data.num_classes # Example number of classes\n",
    "\n",
    "# Create the CNN model\n",
    "model7 = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model7.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 2e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint(filepath='Model_Results/Model_checkpoints/model_7.h5', monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_callback = create_tensorboard_callback(experiment_name=\"Model7\")\n",
    "# Train the model with callbacks\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "history7 = model7.fit(train_data,\n",
    "                    epochs=80,\n",
    "                    validation_data=val_data,\n",
    "                    callbacks=[ model_checkpoint , tensorboard_callback,early_stopping])\n",
    "# End time\n",
    "end_time = time.time()\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# Save training time to a file\n",
    "with open('Model_Results/training_time.txt', 'w') as file:\n",
    "    file.write(f\"Total training time model 7: {training_time} seconds\\n\")\n",
    "# Print model summary\n",
    "model7.summary()\n",
    "\n",
    "model7.save('Model_Results/Models/Model_files/model_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "error",
     "timestamp": 1710046053343,
     "user": {
      "displayName": "BT20ECE074_Chinmay_Patil",
      "userId": "04091258501766783761"
     },
     "user_tz": -330
    },
    "id": "b_qt_B9pq-jU",
    "outputId": "54d6d515-6b12-4336-ded4-8c80a80a1d72"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history7 , 'model_7' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrTMz4mdq-gk"
   },
   "outputs": [],
   "source": [
    "model7 = tf.keras.models.load_model('Model_Results/Models/Model_files/model_7')\n",
    "model7.load_weights('Model_Results/Model_checkpoints/model_7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8auXh6a2q-du"
   },
   "outputs": [],
   "source": [
    "accuracy , precision , recall = Ploting_Confusion_matrix(test_data , model7 , 'model_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1V5S6mFizx1a"
   },
   "outputs": [],
   "source": [
    "Some_Predictions_on_Test_Data(test_dir , class_names , model7 , True ,'Model_7' , save_dir =\"Model_Results/Some_Predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUNb937artLk"
   },
   "outputs": [],
   "source": [
    "# Example data to append\n",
    "num_epochs_trained = len(history7.history['loss'])\n",
    "new_row_data = {\"Model_name\": [\"MobileNet\"], \"accuracy\": [accuracy], \"precision\": [precision], \"recall\": [recall], \"training_time\": [training_time], \"epochs\": [num_epochs_trained]}\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Append row to DataFrame and save to CSV\n",
    "append_row_to_dataframe(new_row_data, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeH4o09vr1S6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYPEQZBJr1PS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    base_model = DenseNet121(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(base_model.input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape for image data (height, width, channels)\n",
    "num_classes = test_data.num_classes # Example number of classes\n",
    "\n",
    "# Create the CNN model\n",
    "model8 = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model8.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "model_checkpoint = callbacks.ModelCheckpoint(filepath='Model_Results/Model_checkpoints/model_8.h5', monitor='val_accuracy', save_best_only=True)\n",
    "tensorboard_callback = create_tensorboard_callback(experiment_name=\"Model5\")\n",
    "# Train the model with callbacks\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "history8 = model8.fit(train_data,\n",
    "                    epochs=80,\n",
    "                    validation_data=val_data,\n",
    "                    callbacks=[ model_checkpoint , tensorboard_callback,early_stopping])\n",
    "# End time\n",
    "end_time = time.time()\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "# # Save training time to a file\n",
    "# with open('Model_Results/Training_time/training_time8.txt', 'w') as file:\n",
    "#     file.write(f\"Total training time model 8: {training_time} seconds\\n\")\n",
    "# Print model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.summary()\n",
    "\n",
    "model8.save('Model_Results/Models/Model_files/model_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHMFaZLvr1MY"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history8 , 'model_8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zh3c8ctMr1JJ"
   },
   "outputs": [],
   "source": [
    "model8 = tf.keras.models.load_model('Model_Results/Models/Model_files/model_8')\n",
    "model8.load_weights('Model_Results/Model_checkpoints/model_8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fkLESfcr1Fu"
   },
   "outputs": [],
   "source": [
    "accuracy , precision , recall = Ploting_Confusion_matrix(test_data , model8 , 'model_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvqHVBfRz2gW"
   },
   "outputs": [],
   "source": [
    "Some_Predictions_on_Test_Data(test_dir , class_names , model8 , True ,'Model_8' , save_dir =\"Model_Results/Some_Predictions\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4MkeYDVr1DR"
   },
   "outputs": [],
   "source": [
    "# Example data to append\n",
    "num_epochs_trained = len(history8.history['loss'])\n",
    "new_row_data = {\"Model_name\": [\"DenseNet\"], \"accuracy\": [accuracy], \"precision\": [precision], \"recall\": [recall], \"training_time\": [training_time], \"epochs\": [num_epochs_trained]}\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"model_metrics.csv\"\n",
    "\n",
    "# Append row to DataFrame and save to CSV\n",
    "append_row_to_dataframe(new_row_data, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4eNJvmar1Ar"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
